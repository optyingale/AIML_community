{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you have all finished week 3 assignements with zeal as it is important to know about algorithms before we actually start applying to our dataset. This is the final week of our assignment and after this, we shall be doing final evaluation of your submissions and then providing you respective certificates.\n",
    "\n",
    "We will start with applying the models, I will aplly logistic regression and explain things accordingly, your assignment for this week is to apply the rest two classifier models to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"cancer dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_Y=LabelEncoder()\n",
    "df.iloc[:,1]=labelencoder_Y.fit_transform(df.iloc[:,1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,2:31].values \n",
    "Y=df.iloc[:,1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X,Y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will start off by creating a function for applying logistic regression to our data. We will use the in-built modules present in the scikit learn library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg (X_train, Y_train):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    log=LogisticRegression(random_state=0, n_jobs=-1)\n",
    "    log.fit(X_train, Y_train)\n",
    "    print(\"Logistic Regression Training Accuracy:\", log.score(X_train, Y_train))\n",
    "    return log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be seeing random state in the code. What is random state used for?\n",
    "\n",
    "If there is no randomstate provided the system will use a randomstate that is generated internally. So, when you run the program multiple times you might see different train/test data points and the behavior will be unpredictable. In case, you have an issue with your model you will not be able to recreate it as you do not know the random number that was generated when you ran the program.\n",
    "\n",
    "### If these codes are a bit overwhelming at the moment, do not worry, you will be doing Decision Tree classifier and Random Forest classifier on your own. Then it will be clearer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Accuracy: 0.9906103286384976\n"
     ]
    }
   ],
   "source": [
    "logrex=logreg(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above given accuracy is when we apply the algorithm to the data which we have used for training, it is much obvious that it will be very close to 100% because we are training with that data. We will be finding out the accuracy of the testing data with the help of confusion matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will apply this algorithm to our testing data as we had earlier applied to the training set and create a confusion matrix. \n",
    "\n",
    "### Confusion Matrix \n",
    "\n",
    "A confusion matrix is a summary of prediction results on a classification problem. The number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix. The confusion matrix shows the ways in which your classification model is confused when it makes predictions. It gives us insight not only into the errors being made by a classifier but more importantly the types of errors that are being made.\n",
    "\n",
    "#### Definition of the Terms:\n",
    "\n",
    "Positive (P) : Observation is positive (for example: is an apple).\n",
    "Negative (N) : Observation is not positive (for example: is not an apple).\n",
    "True Positive (TP) : Observation is positive, and is predicted to be positive.\n",
    "False Negative (FN) : Observation is positive, but is predicted negative.\n",
    "True Negative (TN) : Observation is negative, and is predicted to be negative.\n",
    "False Positive (FP) : Observation is negative, but is predicted positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rates that are often computed from a confusion matrix for a binary classifier:\n",
    "\n",
    "Accuracy: Overall, how often is the classifier correct?\n",
    "(TP+TN)/total\n",
    "\n",
    "Misclassification Rate: Overall, how often is it wrong?\n",
    "(FP+FN)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[86  4]\n",
      " [ 3 50]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, logrex.predict(X_test))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model\n",
    "1. true positive=86\n",
    "2. True negative=50\n",
    "3. False positive=4\n",
    "4. False negative=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy of logistic regression model= 0.951048951048951\n"
     ]
    }
   ],
   "source": [
    "TP=cm[0][0]\n",
    "TN=cm[1][1]\n",
    "FN=cm[1][0]\n",
    "FP=cm[0][1]\n",
    "print(\"Testing accuracy of logistic regression model=\", (TP+TN)/(TP+TN+FN+FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, I have applied the logistic regression model to our data. Now it is your turn to apply Decision tree classifier and Random forest classifier to this data and find out the accuracy of the model using confusion matrix as shown above and also comment on which model had higher accuracy and why. You can find the codes for applying these models online, please use them!\n",
    "With this, we come towards the end of the project and in week 5, we will be doing your final evaluation, taking feedbacks from you all and providing you certificates. \n",
    "All the best and hope we will do more projects in future! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Training Accuracy:  1.0 \n",
      "\n",
      "# ----- Testing ----- #\n",
      "\n",
      "Accuracy ...............  0.9370629370629371\n",
      "Misclassification Rate ...  0.06293706293706294\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0, criterion = \"entropy\").fit(X_train,Y_train)\n",
    "\n",
    "print(\"Decision Tree Training Accuracy: \", clf.score(X_train, Y_train),'\\n')\n",
    "# Alternative for confusion matrix\n",
    "# print(\"Decision Tree Testing Accuracy: \", clf.score(X_test, Y_test),'\\n') \n",
    "\n",
    "cm = confusion_matrix(Y_test, clf.predict(X_test))\n",
    "TP=cm[0][0]\n",
    "TN=cm[1][1]\n",
    "FN=cm[1][0]\n",
    "FP=cm[0][1]\n",
    "print(\"# ----- Testing ----- #\")\n",
    "print(\"\\nAccuracy ............... \", (TP+TN)/(TP+TN+FN+FP))\n",
    "\n",
    "print(\"Misclassification Rate ... \", (FN+FP)/(TP+TN+FP+FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Accuracy:  1.0 \n",
      "\n",
      "# ----- Testing ----- #\n",
      "\n",
      "Accuracy ...............  0.9790209790209791\n",
      "Misclassification Rate ...  0.02097902097902098\n"
     ]
    }
   ],
   "source": [
    "# Random Tree Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0, n_jobs=-1, criterion='entropy', n_estimators=100).fit(X_train,Y_train)\n",
    "\n",
    "print(\"Random Forest Training Accuracy: \", clf.score(X_train, Y_train),'\\n')\n",
    "\n",
    "cm = confusion_matrix(Y_test, clf.predict(X_test))\n",
    "TP=cm[0][0]\n",
    "TN=cm[1][1]\n",
    "FN=cm[1][0]\n",
    "FP=cm[0][1]\n",
    "print(\"# ----- Testing ----- #\")\n",
    "print(\"\\nAccuracy ............... \", (TP+TN)/(TP+TN+FN+FP))\n",
    "\n",
    "print(\"Misclassification Rate ... \", (FN+FP)/(TP+TN+FP+FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "#### Random Forest Classifier and Decision Tree Classifier have the same training set accuracy i.e. 1.0 but for testing data Random Forest scores better than Decision Tree by 0.042 \n",
    "##### Since Random Forest is an ensemble of multiple decision trees based on random sample of training data, generally random forests gives a better accuracy without overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
